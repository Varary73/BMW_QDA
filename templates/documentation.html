<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.4.1, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.4.1, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="{{ url_for('static', filename='assets/images/qda-logo-3-128x128.png') }}" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Documentation</title>
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/web/assets/mobirise-icons2/mobirise2.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/bootstrap/css/bootstrap.min.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/bootstrap/css/bootstrap-grid.min.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/bootstrap/css/bootstrap-reboot.min.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/dropdown/css/style.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/socicon/css/styles.css') }}">
  <link rel="stylesheet" href="{{ url_for('static', filename='assets/theme/css/style.css') }}">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="{{ url_for('static', filename='assets/mobirise/css/mbr-additional.css') }}"><link rel="stylesheet" href="{{ url_for('static', filename='assets/mobirise/css/mbr-additional.css') }}" type="text/css">
  
  
  
  
</head>
<body>
  
  <section data-bs-version="5.1" class="menu menu1 cid-sIrxHTnKws" once="menu" id="menu1-7">
    

    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container-fluid">
            <div class="navbar-brand">
                <span class="navbar-logo">
                    <a href="/">
                        <img src="{{ url_for('static', filename='assets/images/qda-logo-3-96x96.png') }}" alt="QDA" style="height: 3rem;">
                    </a>
                </span>
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black text-primary display-7" href="/">QDA</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbarSupportedContent" data-bs-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="/#team1-2">Our team</a></li>
                    
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="/documentation">Documentation</a>
                    </li></ul>
                
                <div class="navbar-buttons mbr-section-btn"><a class="btn btn-primary display-4" href="/live_demo">Live Demo</a></div>
            </div>
        </div>
    </nav>
</section>

<section data-bs-version="5.1" class="tabs content18 cid-sJyiPNudy8" id="tabs1-k">

    

    <div class="mbr-overlay" style="opacity: 0.5; background-color: rgb(0, 0, 0);">
    </div>
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-8">
                <h3 class="mbr-section-title mb-0 mbr-fonts-style display-2">
                    <strong>Models</strong></h3>
                <h4 class="mbr-section-subtitle mb-0 mt-2 mbr-fonts-style display-7">
			Project - QDA focuses on developing machine learning models for image processing based on the presented dataset. The methods of Classical and Quantum machine learning have proved to be very accurate for image classification and as a result, these models are being implemented in this project in order to build a high-performance solution for Surface Crack Detection.
			<br><br>
			The use of the two different versions with classical and quantum computing has allowed us to compare and get an insight into the performances of each model. Since it is a tendency of classical computers to reach their limits, Project - QDA aims to see if quantum computing can be a viable alternative in the future (and even in the present) with the rapidly developing technology. 
			<br><br>
			The aim behind the exploration of quantum techniques in such challenges is to be able to outperform classical methods thanks to the properties of quantum mechanics. Indeed, quantum computing could represent a large cut in cost due to the use of large image datasets that are very expensive to store, process and analyze. With the development of QRAM as a new way to store data, it could be possible to access large amounts of data with low energy and very easily. Moreover, quantum computing is said to give exponential speedup over classical processes. Finally, another key element in the role of quantum mechanics in computing is the ability to perform operations that are not conceivable by classical computers. This gives new ways to understand how data can be analyzed by quantum architectures to reveal other kinds of valuable information. 
			<br><br>
			More importantly, this is an industrial challenge to overcome in order to be even more efficient than today with quantum computers. That is why this study focused on quantum computing to elaborate on new real-life applications to common problems. Thus, when the technology has matured enough, it will be possible to integrate it easily into this new industry and benefit from the quantum advantages.
		</h4>
            </div>
        </div>
        <div class="row justify-content-center mt-4">
            <div class="col-12 col-md-8">
                <ul class="nav nav-tabs mb-4" role="tablist">
                    <li class="nav-item first mbr-fonts-style"><a class="nav-link mbr-fonts-style show active display-7" role="tab" data-toggle="tab" data-bs-toggle="tab" href="#tabs1-k_tab0" aria-selected="true"><strong>Classical CNN</strong></a></li>
                    <li class="nav-item"><a class="nav-link mbr-fonts-style active display-7" role="tab" data-toggle="tab" data-bs-toggle="tab" href="#tabs1-k_tab1" aria-selected="true"><strong>Hybrid QNN</strong></a></li>
                    <li class="nav-item"><a class="nav-link mbr-fonts-style active display-7" role="tab" data-toggle="tab" data-bs-toggle="tab" href="#tabs1-k_tab2" aria-selected="true"><strong>QNN+QCA</strong></a></li>
                    
                    
                    
                </ul>
                <div class="tab-content">
                    <div id="tab1" class="tab-pane in active" role="tabpanel">
                        <div class="row">
                            <div class="col-md-12">
                                <p class="mbr-text mbr-fonts-style display-7">
					A classical Convolution Neural Network (CNN) is made using the Pytorch library for convenient data transformation as well as its compatibility with Qiskit modules that will be useful to develop the quantum model. Indeed, Pytorch has a native connector for Qiskit which reduces the development overhead and augments the model creation process.
					<br><br>
					For this specific implementation, a pre-trained ResNet50 model is used and re-purposed for the surface crack detection datasets by implementing it using transfer learning. Transfer learning is a method where we take a pre-trained model on a given task and train it again to perform on another task. As we can see on the image, we have the ResNet50 model presented that was previously trained. After that, we use in our situation the images presented before to train it again.
					<img src="{{ url_for('static', filename='assets/images/CNN1.png') }}" alt="">
					In our situation, model parameters were untouched and an Adam optimizer with a default learning rate was utilized. The model was retrained for 19 epochs on the training data set sample while measuring loss and accuracy on the validation set. The summary of the final model used for the experimentations is shown in the following image.
					<img src="{{ url_for('static', filename='assets/images/CNN2.png') }}" alt="">
					At the end of the training process, we obtain the following evolution for the loss function.
					<img src="{{ url_for('static', filename='assets/images/CNN3.png') }}" alt="">
					Thus the negative log-likelihood loss function oscillates between 0.55 and 0.50 after some iterations. At this stage, it is better to take an iteration close to 0.50 because the model will not learn more. This gives a training accuracy of 0.8431 on the training set composed of 1587 images and 413 for the validation set. This gives a lot of left images to form new datasets at each epoch with the same length but only different images.
					<img src="{{ url_for('static', filename='assets/images/CNN4.png') }}" alt="">
					This image is represented the testing accuracy along with the training. As we can see, the train and validation accuracy is very close with a maximum of 0.939467 for validation. This allows us to have a strong classical model for the image classification between the negative label with no cracks and the positive label with cracks. In the end, the results are shown here when the model is presented with new data images.
					<img src="{{ url_for('static', filename='assets/images/CNN5.png') }}" alt="">
					The model is built to only highlight the crack zones of the images. Thus we can see that for the left image labelled Negative, the whole image is green which indicates the model has detected no cracks. The image is predicted as Negative. On the right, the model also detected the no crack zones that appear in green but some areas are red indicating the detection of cracks. The image is predicted as Positive and the model specifies precisely the location of the cracks. 
					<br><br>
					In the context of industrialization, it is not enough for a model to detect only that there are cracks on a shown image of an assembly piece. Indeed, if we want to fix it or change only the corresponding part of the piece, it is necessary to have the precise location of the crack on the image. 
                                </p>
                            </div>
                        </div>
                    </div>
                    <div id="tab2" class="tab-pane" role="tabpanel">
                        <div class="row">
                            <div class="col-md-12">
                                <p class="mbr-text mbr-fonts-style display-7">
					<strong>Quantum-classical Neural Networks with PyTorch and Qiskit:</strong>
					<br><br>
					Quantum Neural Networks (QNNs) are computational neural network models which are based on the principles of quantum mechanics and act application-agnostic computational units that can be used for many different use cases, such as Image Processing, Natural Language Processing, computer games, function approximation, handling big data, in modelling social networks, associative memory devices, and automated control systems etc.
					<br><br>
					For this stage, a hybrid QNN model is prepared simultaneously using Pytorch and Qiskit. The approach was to use a classical Neural network and add in a few quantum layers which are in practice, governed by a pre-set quantum circuit. This complete implementation is trained with the same surface crack dataset mentioned previously. Here 1000 positive and negative crack images are taken rather than 20000 for training reasons. There were some complications involved with access time and resource allocation on our IBM backend which warranted a decrease in resolution of the samples and the size of the training set. 
					<br><br>
					<strong>Creating a "Quantum Class" with Qiskit:</strong>
					<br><br>
					The customized quantum circuit for the QNN model was made by preparing a quantum class using a simple quantum circuit with RY−rotation by the angle 𝜽 to train the output of our circuit. 
					<img src="{{ url_for('static', filename='assets/images/QNN1.png') }}" alt="">
					To measure the output in the z−basis, we calculate the σz expectation as:
					<img src="{{ url_for('static', filename='assets/images/QNN2.png') }}" alt="">
					After implementing this the calculated expected value comes out to be 0.54. 
					<br><br>
					<strong>Creating a "Quantum-Classical Class" with PyTorch:</strong>
					Now after defining the quantum circuit, the functions needed for back-propagation are created using PyTorch. The forward and backward passes contain elements from the created Qiskit class. The backward pass directly computes the analytical gradients using the finite difference formula.
					<br><br>
					<strong>Data Loading and Preprocessing and training the network:</strong>
					<br><br>
					We have loaded the data and coded a class that creates our quantum circuit which contains 1 trainable parameter. This quantum parameter will be inserted into a classical neural network along with the other classical parameters to form the hybrid neural network. We also created backwards and forward pass functions that allow us to do backpropagation and optimise our neural network. Lastly, we need to specify our neural network architecture such that we can begin to train our parameters using optimization techniques provided by PyTorch.
					<br><br>
					<strong>Creating the Hybrid Neural Network and training:</strong>
					<br><br>
					The network will need to be compatible in terms of its dimensionality when the quantum layer (such that in the quantum circuit) will be inserted. Since the quantum circuit in this paper contains 1 parameter, the network should condense neurons down to size 1. A typical Convolutional Neural Network with two fully connected layers at the end is made up. The value of the last neuron of the fully connected layer is fed as the parameter 𝜽 into our quantum circuit. The circuit measurement then serves as the final prediction for 0 or 1 as provided by a σz measurement. Now by using Adam PyTorch optimiser, the learning rate is 0.001 and negative log-likelihood loss function to train over multiple epochs.
					<br><br>
					<strong>Results:</strong>
					<br><br>
					The model was retrained for 19 epochs on the training data set sample while measuring loss and accuracy on the validation set. The summary of the final model used for the experimentations is shown in the following image.
					<img src="{{ url_for('static', filename='assets/images/QNN3.png') }}" alt="">
					At the end of the training process, we obtain the following evolution for the loss function.
					<br><br>
					<strong>Define Optimizer and Loss Function:</strong>
					<br><br>
					Learning rate decay- As we train the model, we can decide to change the learning rate dynamically. The scheduler helps us in doing that. In the 1st epoch, the learning rate was 0.1, then the learning rate in epoch 4 would be 0.01.
					<br>
					Considerations are:
					<br>
					5 layer NN, Image input resolution = 6x6, Scaling Method: LANCZOS, Train Dataset size = 159, Test Dataset size = 39, Image channels = 1, Hybrid fully connected quantum layers = 1, Simulator =aer_simulator, No of Qubits = 1.
					<img src="{{ url_for('static', filename='assets/images/QNN4.png') }}" alt="">
					This gives a training accuracy of 0.8599 on the training set composed of 159 images for the situation and the rest is for testing and validation.
					<img src="{{ url_for('static', filename='assets/images/QNN5.png') }}" alt="">
					Training accuracy: 85.99%  and  Validation accuracy: 95.02% 
					<br>
					This image is represented the testing accuracy along with the training. As we can see, the training accuracy is lesser with a final score of 0.8599 compared to the testing accuracy. This allows us to have a hybrid model for the image classification between the negative label with no cracks and the positive label with cracks.
					<br><br>
					These are the results displayed at the end of the analysis on new images of the dataset.
					<img src="{{ url_for('static', filename='assets/images/QNN6.png') }}" alt="">
					The model is built to only highlight the crack zones of the images. Thus we can see that for the left image labelled Negative, the whole image is green which indicates the model has detected no cracks. The image is predicted as Negative. On the right, the model also detected the no crack zones that appear in green but some areas are red indicating the detection of cracks. The image is predicted as Positive and the model specifies precisely the location of the cracks. 
				</p>
                            </div>
                        </div>
                    </div>
                    <div id="tab3" class="tab-pane" role="tabpanel">
                        <div class="row">
                            <div class="col-md-12">
                                <p class="mbr-text mbr-fonts-style display-7">
Collaboration has always been an important concept in the scientific community. In addition to using the built-in programs, a new dimension can come up with Qiskit ML programs that can help and accelerate the progress in research.
<br>In Quantum Machine Learning (QML), Quantum kernels is the approach of exploiting group structure in data which helps to achieve quantum speedup. Quantum kernels can be optimized with a technique called kernel alignment. QNN is parameterized quantum circuits which act like linear methods in quantum feature space and suitable for using quantum kernels and in turn can be optimized using Quantum Kernel Alignment. An attempt is made to demonstrate the application of using QKA with QNN networks in the model to have augmented training or performance improvement. Quantum kernels are used in a classification framework to inherit the convex optimization program and avoid common limitations of variational quantum classifiers. As QKA optimizes the Quantum Kernel Estimation, in turn it helps QNN sort programs to achieve higher generalization of accuracy and highly required in Automated Quality Management based on Image Processing.
<br>The CircuitQNN is based on a (parametrized) QuantumCircuit. This can take input as well as weight parameters and produces samples from the measurement. The samples can either be interpreted as probabilities of measuring the integer index corresponding to a bitstring or directly as a batch of binary output. In the case of probabilities, gradients can be estimated efficiently and the CircuitQNN provides a backward pass as well. In case of samples, differentiation is not possible and the backward pass returns (None, None).
                                </p>
                            </div>
                        </div>
                    </div>
                    
                    
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="features19 cid-sJyj7M1eJI" id="features20-l">

    
    <div class="mbr-overlay" style="opacity: 0.8; background-color: rgb(255, 255, 255);">
    </div>
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9">
                <div class="card-wrapper pb-4">
                    <div class="card-box align-center">
                        <h4 class="card-title mbr-fonts-style mb-4 display-2">
                            <strong>Industry Scalability</strong></h4>
                        <p class="mbr-text mbr-fonts-style mb-4 display-7">
                            This study was the opportunity to experiment both classical and quantum models for image analysis. However, the use case extends beyond the research field. Indeed, this challenge arises from BMW's report that their current method for quality assessment has to be improved in order to perform even more in the assembly line. Thus, this image analysis study grows in the context of industry applicability and scalability to show if new methods could be more efficient to current automated quality  assessment methods.

In this manner, because we are reaching the limits of classical computers, the industry is searching for new ways to improve those methods. To do so, this study focused on quantum neural networks to compare to convolutional neural networks in order to compare those methods. As we are at the beginning of quantum technology, it is important to analyze what is possible or not and what can be imagined for industry scalability in the future.

			</p>
                        
                    </div>
                </div>
            </div>
            <div class="col-12 col-md-8">
                <div class="item mbr-flex">
                    <div class="icon-box">
                        <span class="step-number mbr-fonts-style display-5">1</span>
                    </div>
                    <div class="text-box">
                        <h4 class="icon-title card-title mbr-black mbr-fonts-style display-7">
                            <strong>Specification</strong>
                        </h4>
                        <h5 class="icon-text mbr-black mbr-fonts-style display-4">abcd</h5>
                    </div>
                </div>
                <div class="item mbr-flex">
                    <div class="icon-box">
                        <span class="step-number mbr-fonts-style display-5">2</span>
                    </div>
                    <div class="text-box">
                        <h4 class="icon-title card-title mbr-black mbr-fonts-style display-7">
                            <strong>Project Planning</strong>
                        </h4>
                        <h5 class="icon-text mbr-black mbr-fonts-style display-4">abcd</h5>
                    </div>
                </div>
                <div class="item mbr-flex last">
                    <div class="icon-box">
                        <span class="step-number mbr-fonts-style display-5">3</span>
                    </div>
                    <div class="text-box">
                        <h4 class="icon-title card-title mbr-black mbr-fonts-style display-7">
                            <strong>Deployment</strong>
                        </h4>
                        <h5 class="icon-text mbr-black mbr-fonts-style display-4">abcd</h5>
                    </div>
                </div>
                
                
                
                
                
                
                
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="footer7 cid-sIrz3is4Gp" once="footers" id="footer7-8">

    

    

    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="col-12">
                <p class="mbr-text mb-0 mbr-fonts-style display-7">~ a collaborative effort by the Quantum Musketeers</p>
            </div>
        </div>
    </div>
</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/o" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;"><a href="https://mobirise.site/c" style="color:#aaa;">The</a> page was designed with Mobirise</p></section><script src="{{ url_for('static', filename='assets/bootstrap/js/bootstrap.bundle.min.js') }}"></script>  <script src="{{ url_for('static', filename='assets/smoothscroll/smooth-scroll.js') }}"></script>  <script src="{{ url_for('static', filename='assets/ytplayer/index.js') }}"></script>  <script src="{{ url_for('static', filename='assets/dropdown/js/navbar-dropdown.js') }}"></script>  <script src="{{ url_for('static', filename='assets/mbr-tabs/mbr-tabs.js') }}"></script>  <script src="{{ url_for('static', filename='assets/theme/js/script.js') }}"></script>  
  
  
</body>
</html>
